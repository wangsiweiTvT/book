### 状态空间 $\mathcal{S}$



### 行为空间$\mathcal{A}(s)$

在某一状态 $s$ 下，可采取行为 $ a_1,a_2,a_3...$ 的集合



### 即时奖励$\mathcal{R}(s,a)$

|  🐱   |  🐀   |  🧀   |
| :--: | :--: | :--: |



在状态 $s$ 下，采取行为 $a$ ,得到的即时奖励。比如一只小老鼠在一张网格中某个网格$(s)$下，采取向右走的动作$(a_1)$,我就能走到奶酪网格中，那么此时得到的奖励是正数 $r(s,a_1)$，如果它采取向左走的动作，它会遇见一只猫，那么即时奖励是负数$r(s,a_2)$。



### 模型(Model)

$p(s'|s,a)$从某一状态$s$ 采取某一行为 $a$ 进入到下一个状态$s'$的概率。并且有：
$$
\sum_{s'\in \mathcal{S}}p(s'|s,a)=1
$$
$p(r|s,a)$从某一状态$s$ 采取某一行为 $a$ ，得到的即时奖励为 $r$ 的概率。并且有：
$$
\sum_{r\in \mathcal{R(s,a)}}p(r|s,a)=1
$$


### 策略(Policy)

$\pi(a|s)$ 一个条件概率，在状态 $s$ 下采取某一行为的概率。并且有：
$$
\sum_{a\in \mathcal{A(s)}}\pi(a|s)=1
$$

### 马尔科夫性质(Markov property)

无记忆性(memoryless):只和最近的状态有关
$$
p(s_{t+1}|s_t,a_t,s_{t-1},a_{t-1},...,s_0,a_0)=p(s_{t+1}|s_t,a_t),\\
p(r_{t+1}|s_t,a_t,s_{t-1},a_{t-1},...,s_0,a_0)=p(r_{t+1}|s_t,a_t),
$$
