---
layout: post
title: 反向学习
---

除了直接学习 Reward，还可以从示例中学习奖励函数。这就是反向强化学习。

## 课程材料

- 滑铁卢 CS885 RL PPT
- Berkeley CS285 Lec 20: Inverse Reinforcement Learning, [slides](https://rail.eecs.berkeley.edu/deeprlcourse/), [Youtube Video](https://www.youtube.com/playlist?list=PL_iWQOsE6TfVYGEGiAOMaOzzv41Jfm_Ps)
- Berkeley Deep RL Bootcamp 2017, Lecture 10b Inverse RL -- Chelsea Finn ([video](https://youtu.be/d9DlQSJQAoI) | [slides](https://drive.google.com/file/d/0BxXI_RttTZAhNjN4SnNYYldqTjQ/view?usp=sharing&resourcekey=0-4WaUMwWNngIT-wqLFFD_Hw))

## 论文

滑铁卢 Inverse RL
- Ziebart, B. D., Bagnell, J. A., & Dey, A. K. (2010). Modeling interaction via the principle of maximum causal entropy. In ICML.
- Finn, C., Levine, S., & Abbeel, P. (2016). Guided cost learning: Deep inverse optimal control via policy optimization. In ICML (pp. 49-58).

## 课本材料

N/A

## 练习

N/A

<br/>

|[Index](index) | [Previous](17-reward) | [Next](19-model-rl) |
