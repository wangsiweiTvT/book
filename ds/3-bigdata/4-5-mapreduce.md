---
layout: post
title: MapReduce
---

本节介绍 MapReduce 分布式计算模型。它能够实现大数据的分布式处理。

## Map Reduce 基本概念

Map 和 Reduce 是一种基本的计算模式。它在 Python 里就有。让我们来看下面的 Python 示例：

```py
>>> list(map(lambda x: x * x, [1, 2, 3]))
[1, 4, 9]

>>> from functools import reduce
>>> reduce(lambda x,y: x + y, [1, 2, 3])
6
```

如上面的代码所示，map 就是把输入数组（即 [1, 2, 3]）里的元素，依次送入 lambda 函数进行计算，并把结果也依次输出。而 reduce，是先把输入数组（即 [1, 2, 3]）里的前两个元素（即 1 和 2），送入 lambda 函数进行计算，得到 1 + 2 = 3，然后再在输入数组中，取下一个元素（即 3），然后把这个 3 和前面计算得到的结果 3，又送入 lambda 函数进行计算，这样就得到了 3 + 3 = 6。依次类推，直到整个输入的数组都计算完。所以，reduce 的操作，有点像滚雪球：它把前面滚出的结果，又送入函数，接着滚，直到整个数组都被滚完，然后把最后计算的结果输出。

## MapReduce 分布式计算范式

在分布式系统中，Map Reduce 是一种编程范式。它有两个步骤：第一个步骤是 Map，第二个步骤就是 Reduce。

我們給大家舉一個例子来說明 Map Reduce。这个例子是單詞計數。假设我們有很多的文档。我们想要统计这些文档里各个单词出现的次数。

我们首先分词。如果是英文文档的话，我们就拿空格就能够分出来一个个单词。中文的话，咱们先要用分词的工具把文本分为一个个词。

我们然后统计单词出现的次数。大家看，文档一，文档二，...，我们有很多文档。不同文档存在不同的计算机里。因为一台计算机即有存储，又有 CPU 可以计算，所以咱们首先把文档用存储它的计算机做 Map。用文档一的电脑做文档一的 Map，文档二的电脑做文档二的 Map。这个 Map 的工作，就是各自统计各自的文档中单词出现的次数。所以这个中间结果呢，就是电脑一，它发现词汇一在它存的文档里出现了几次，词汇二出现了几次，词汇三出现了几次，等等。电脑二也计算了，发现词汇一在它存的文档里出现了几次，词汇二出现了几次，词汇三出现了几次，等等。然后呢，我们就做 Reduce，就是把这些电脑的结果再加起来，得到词汇一总共发生了几次。这就算出了所有文档中每个单词出现次数的总和了呀。

## Map Reduce 计算的性能特点

这种 Map Reduce 分布式计算的方式，需要对数据进行网络传输。它首先由很多电脑，对本机的数据执行 Map 操作，然后把得到的中间结果，提供网络送到另一个机器上去做 Reduce 操作。

执行分布式计算时，数据在机器间通过网络传输最花时间。因为我们要计算的数据在一个电脑上存不下，要存到十台电脑里，所有我们需要用一个网络交换机把这十台电脑连到一起。这时，在这些电脑之间，通过网络传输中间结果的速度，就比我们访问本地内存或者磁盘的速度，慢多了。如果有一百台电脑的话，那一个交换机的端口数就不够了，不能用一个交换机把它们全部连在一起。这时，我们需要在一级交换机上面，再加一层交换机。这样传输速度就更慢了。如果一千台电脑的话，很可能你这个电脑在这个楼层，另外一个电脑是在下面的楼层，这样距离就更远，传输速度就更慢了。

Map Reduce 让一个电脑在本地执行 Map 操作，尽量避免了数据在机器间的传输。你看，在上面的单词计数的例子中，该统计的，我都本地统计完了，最后只不过是把这个结果送到另一台电脑上去加一下。相比于把整个文件传到另一台电脑上去统计，传输这个统计的结果，所传输的数据量就大大地减少了，所消耗的时间也大大减少了。我用不着把这个电脑的文档送到那个电脑去，让那个电脑去算，而是本地算好，减少节点之间的通信。所以它的速度会快一些。

所以，Map Reduce 在计算上是并行的：同时有很多电脑在同时对本地文档进行计算。这些计算是并行的。然后呢，它的速度还提高了，因为它是把中间结果在网络上传输，避免了原始文档这些大的数据在网络上传输。大家现在在电脑上用 U 盘拷贝 1 G 的文件，还要拷个一分钟呢，对吧？如果你要通过一个网络，即使它是千兆的网络，你也要传很久很久。这个数据如果是一个 P 怎么办？是很慢的。通过 Map Reduce 的方法，就能够加速大数据的处理。这就是Map Reduce 的最基本的概念。

## Map Reduce 的具体实现

我们下面介绍 Map Reduce 的具体实现。我们还是使用上述单词计数的例子，但是介绍其具体的实现细节。

第一步是 Map。在具体的实现中，Map 的输出是“键值对”（Key-Value Pair）。比如单词计数的 Map，它就把文档里面的一个个单词啊，转变为“键值对”。 Key 是这个单词，值是数字 1。文档里有几个单词，它就输出几个键值对。举例来说，假设这个文档的文本是 “big document” 这两个单词。 Map 操作特别简单，就是见到 big 这个单词，就拿它的文本作 Key，对应的 Value 也特别简单，就是数字 1，所以就输出 <"big",1>。然后见到 document 这个单词，它也输出一个 <"document", 1>。所以这个 Map 的逻辑是超简单的。那么，如果这个文档里还有一个 document 的单词，怎么办呢？它还输出一个 <"document", 1>。为什么不输出 <"document", 2> 呢？也可以，但这样的话，我们的 Map 操作的逻辑就要复杂一些。我们先按这个简单的来介绍。所以对于文本“big document document”，我们就会得到三个键值对：<"big", 1>、<"document", 1>、<"document", 1>。所以这个 Map 函数让大家写的话，是不是很简单、很好写？就是用一个 for 循环，不断读这段文本里的单词。见一个单词，就往外塞一个键值对，就可以了嘛。这个代码三四行就出来了，很好写。

第二步是 Group by Key。这是实现 Map Reduce 计算的大数据软件，比如 Hadoop、Spark，给大家实现的一个特别重要的工作。它是 Hadoop 或者 Spark 自己做的，不需要我们编程。它的作用是：收集所有 Map 节点输出的各种键值对，将它们按照它们的“键”进行分组，然后把一组键值对，交给一个做 Reduce 的节点。因此，它就会把所有 Map 节点输出的以 “big” 为“键”的键值对，都分成一组，交给一个做 Reduce 操作的机器。把所有以 “document” 为“键”的键值对，都分成一组，交给一个做 Reduce 操作的机器。注意，这是 Map Reduce 平台做的事，不需要我们编程。也就是说，Map Reduce 平台帮我们做了这样一个合并的工作。合并完之后，所有相同键的键值对，都被交给一台机器了。比如这里有一千台 Map 机器。它们生成的所有以 “big” 为键的键值对，就被交给一台做 Reduce 的机器了。

第三步是 Reduce。负责 Reduce 的机器，拿着 Map Reduce 平台交给它的一个“键”的所有“键值对”后，它就会做 Reduce 的操作。为此，我们要写一个 Reduce 函数。这个函数的输入是这个一个“键值对”：“键”是这些键值对的共同的“键”，值是一个数组，里面是所有这些键值对的值。比如，Map 产生 <"document", 1> 和 <"document", 1> 这两个键值对，那么 Reduce 的输入是 <"document", [1,1]>。因此，我们就可以在 Reduce 的函数里，对这个“键值对”里的值，做 Reduce 操作。比如“求和”：就 1 + 1，把它们加起来，就得到 “document” 这个单词出现的总次数了。所以 Reduce 这个函数也特别好写。

通过上面这种计算范式，我们就能够对大数据进行编程。我们编写 Map 和 Reduce 这两个函数。它们会在各个机器上各自运行。这就是分布式运行。然后，Map Reduce 的平台做了很多事情。它负责把 Map 输出的“键值对”收集起来。然后，它其实还做了一些其它事情，比如对“值”的数组，做了排序。这个也可以用来达到我们想要的一些效果，但是我们的这个计数的应用用不着。

总之，Map 的作用是读本地存储的文件，进行本地处理，产生很多键值对。然后平台做 Group by Key 操作，把一个Key 的所有键值对，从所有 Map 机器收集起来，把它们的值合并到一个数组里，还对数组里的值进行来排序，然后交给负责这个 Key 的 Reduce 机器。这个 Reduce 机器就对这个 Key 的所有值的数组，进行计算，得到一个输出。这就是 Hadoop、Spark 这些 Map Reduce 大数据平台实现数据计算的方式。

## 小结

我们然后介绍 MapReduce 分布式计算模型。它能够实现大数据的分布式处理。我们介绍它的原理和使用。利用 MapReduce，我们可以在计算机集群上，进行并行处理。其中，Map 会利用本机的CPU，对本地数据做Map操作，输出“键值对”，然后大数据计算框架（如 Hadoop，Spark）会对这些“键值对”做 “Group by Key”，即把相同 Key 的键值对，分成一组，输出：键：值List。然后，一组的输出会被交给一个 Reduce 机器。这个机器就会在“键：值List”上做 Reduce操作。我们将介绍一个大文档的单词计数的例子。其中，Map 会简单地输出 “单词：1”，而 Reduce 会把“单词”的 Value 列表中的“1”累加起来。

<br/>

|[Index](../) | [Previous](4-3-hdfs) | [Next](4-7-mr-lab) |
